# Cultural-Heritage-Story-Teller
ğŸŒŸ Overview
An intelligent AI system that "sees" cultural artifacts and weaves authentic stories about India's rich heritage. This project fine-tunes a Qwen2-VL 2B parameter vision-language model using a groundbreaking 3-stage progressive learning approach on 1,360 diverse regional images spanning India's vast cultural tapestry.

âœ¨ What Makes This Special?
ğŸ¯ Revolutionary 3-Stage Training: Recognition â†’ Understanding â†’ Storytelling

ğŸ—ºï¸ Pan-Indian Coverage: 5 geographical regions (North, South, East, West, Northeast)

ğŸš€ Advanced LoRA Fine-tuning: 85% performance improvement achieved

ğŸ“– Authentic Narratives: Culturally accurate stories preserving heritage

ğŸ’¡ Research Innovation: Novel progressive learning methodology

ğŸ›ï¸ Cultural Impact
"Transforming silent cultural images into vivid, contextual narratives for digital heritage preservation"

This project addresses the critical need for digital cultural preservation by:

ğŸ“š Documenting Stories: Converting visual heritage into textual narratives

ğŸŒ Accessibility: Making cultural knowledge accessible globally

ğŸ”¬ Research Tool: Supporting cultural studies and heritage research

ğŸ“ Education: Enhancing cultural education through AI storytelling

ğŸ“Š Project Highlights
Metric	Achievement
Dataset Size	1,360 curated cultural images
Model Parameters	2B (Qwen2-VL) with LoRA fine-tuning
Performance Improvement	85% loss reduction (130 â†’ 19.7)
Regional Coverage	5 major Indian geographical regions
Training Methodology	3-stage progressive learning
Cultural Accuracy	High-quality, authentic narratives
ğŸ—ï¸ 3-Stage Progressive Architecture
text
ğŸ–¼ï¸ Cultural Image Input
            â†“
    ğŸ‘ï¸ Qwen2-VL Vision Encoder
            â†“
    ğŸ§  Language Model Processing
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Element Recognition  â”‚ â† Identifies cultural elements
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 2: Pattern Understanding â”‚ â† Understands regional context
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Stage 3: Story Generation      â”‚ â† Weaves authentic narratives
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
    ğŸ“– Cultural Story Output
Progressive Learning Stages
ğŸ” Cultural Element Recognition

Identifies temples, sculptures, architectural features

Recognizes traditional clothing, artifacts, decorations

Training: 1 epoch, LR: 2e-4

ğŸ¨ Cultural Pattern Understanding

Understands architectural styles (Dravidian, Mughal, etc.)

Analyzes regional patterns and significance

Training: 1 epoch, LR: 1e-4

ğŸ“š Cultural Story Generation

Generates authentic, contextual narratives

Preserves cultural accuracy and historical context

Training: 2 epochs, LR: 5e-5

ğŸš€ Quick Start
Installation
bash
# Clone the repository
git clone https://github.com/PranavSingla122/Cultural-Heritage-Story-Teller.git
cd Cultural-Heritage-Story-Teller

# Install dependencies
pip install -r requirements.txt

# Install additional requirements for vision-language models
pip install transformers[vision] torch torchvision peft accelerate bitsandbytes

Example Output:

text
This magnificent Dravidian temple showcases the architectural brilliance of Tamil Nadu, 
with its towering gopuram adorned with intricate sculptures depicting celestial beings 
and divine stories. The stone carvings, weathered by centuries of devotion, tell tales 
of ancient rituals and spiritual practices that continue to resonate in South Indian 
culture today...
ğŸ“ Repository Structure
text
Cultural-Heritage-Story-Teller/
â”œâ”€â”€ ğŸ train_progressive.py          # Main 3-stage training pipeline
â”œâ”€â”€ ğŸ”§ continue_training.py          # Optional optimization script
â”œâ”€â”€ ğŸ”® inference.py                  # Story generation from trained model
â”œâ”€â”€ ğŸ“Š dataset_utils.py              # Dataset loading and preprocessing
â”œâ”€â”€ ğŸ›ï¸ config.py                    # Training configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Python dependencies
â”œâ”€â”€ ğŸ“ data/                         # Dataset directory
â”‚   â””â”€â”€ cultural_dataset.json       # Your cultural image dataset
â”œâ”€â”€ ğŸ“ models/                       # Trained model checkpoints
â”‚   â””â”€â”€ cultural_vlm_trained/        # Final trained model
â”œâ”€â”€ ğŸ“ examples/                     # Usage examples and demos
â””â”€â”€ ğŸ“– README.md                     # This file
ğŸ¯ Training Your Own Model
Dataset Format
Your cultural dataset should follow this JSON structure:

json
{
  "image_path": "regional_images/South_India/temple_001.jpg",
  "region": "South_India",
  "real_features": {
    "detected_elements": ["temple", "gopuram", "sculpture"],
    "architecture": {"style": "Dravidian"},
    "colors": {"dominant": ["brown", "red"]},
    "scene": {"type": "religious"}
  },
  "unique_story": "This ancient Dravidian temple stands as a testament...",
  "cultural_context": "South Indian temple architecture represents..."
}
3-Stage Progressive Training
bash
# Run complete 3-stage progressive training
python train_progressive.py

# For testing with limited samples
python train_progressive.py --test_samples 100

# Single stage training (skip progressive approach)
python train_progressive.py --single_stage
Advanced Training Options
python
# Custom configuration
config = CulturalVLMConfig()
config.learning_rate = 2e-4
config.batch_size = 1
config.gradient_accumulation_steps = 16
config.lora_r = 8
config.lora_alpha = 32

# Enable/disable progressive training
config.enable_progressive = True
config.stage1_epochs = 1
config.stage2_epochs = 1  
config.stage3_epochs = 2
ğŸ“ˆ Training Results
Progressive Training Performance
Stage	Task	Loss Reduction	Key Learning
1	Element Recognition	504 â†’ 217	Cultural artifact identification
2	Pattern Understanding	217 â†’ 201	Regional style comprehension
3	Story Generation	184 â†’ 19.7	Authentic narrative creation
Regional Dataset Distribution
ğŸ”ï¸ North India: 160 samples (Rajasthan, Delhi, Himalayas)

ğŸ›ï¸ South India: 400 samples (Tamil Nadu, Karnataka, Kerala)

ğŸ­ East India: 400 samples (West Bengal, Odisha, Jharkhand)

ğŸœï¸ West India: 200 samples (Gujarat, Maharashtra, Rajasthan)

ğŸŒ„ Northeast India: 200 samples (Assam, Meghalaya, Sikkim)

ğŸ› ï¸ Technical Specifications
Model Architecture
Base Model: Qwen2-VL-2B-Instruct

Fine-tuning: LoRA (r=8, Î±=32, 7 target modules)

Quantization: 4-bit with bfloat16 precision

Context Length: 512 tokens

Image Resolution: 336Ã—336 pixels

Training Configuration
Optimizer: AdamW with cosine scheduling

Memory Optimization: Gradient checkpointing + quantization

Hardware Requirements: 8GB+ GPU recommended

Training Time: ~3-5 hours for full pipeline
ğŸ¤ Contributing
We welcome contributions from cultural enthusiasts, AI researchers, and heritage preservationists!

How to Contribute
ğŸ´ Fork the repository

ğŸŒ¿ Create a feature branch

Contribution Areas
ğŸ¨ Dataset Expansion: Adding more regional cultural images

ğŸ”¬ Model Improvements: Enhancing training methodologies

ğŸŒ Multilingual Support: Adding regional language stories

ğŸ“± Applications: Building demo apps and interfaces

ğŸ“– Documentation: Improving guides and examples

ğŸ“œ License
This project is licensed under the Apache License 2.0 - see the LICENSE file for details.

Usage Rights
âœ… Commercial Use: Permitted

âœ… Modification: Permitted

âœ… Distribution: Permitted

âœ… Patent Use: Permitted

âš ï¸ Trademark Use: Not permitted

â­ Star this repository if it helped preserve cultural heritage through AI!
"Building bridges between ancient wisdom and modern technology"
