# ğŸŒŸ Cultural Heritage Story Teller

<div align="center">

![GitHub stars](https://img.shields.io/github/stars/PranavSingla122/Cultural-Heritage-Story-Teller?style=social)
![GitHub forks](https://img.shields.io/github/forks/PranavSingla122/Cultural-Heritage-Story-Teller?style=social)
![GitHub issues](https://img.shields.io/github/issues/PranavSingla122/Cultural-Heritage-Story-Teller)
![License](https://img.shields.io/github/license/PranavSingla122/Cultural-Heritage-Story-Teller)

**An intelligent AI system that "sees" cultural artifacts and weaves authentic stories about India's rich heritage**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“Š Features](#-what-makes-this-special) â€¢ [ğŸ—ï¸ Architecture](#ï¸-3-stage-progressive-architecture) â€¢ [ğŸ¤ Contributing](#-contributing) â€¢ [ğŸ“œ License](#-license)

</div>

---

## ğŸ¯ Overview

This project fine-tunes a **Qwen2-VL (2B parameters)** vision-language model using a **3-stage progressive learning approach** on **1,360 diverse regional images** spanning India's vast cultural tapestry. Transform silent cultural images into vivid, contextual narratives for digital heritage preservation.

## âœ¨ What Makes This Special?

- ğŸ¯ **Revolutionary 3-Stage Training**: Recognition â†’ Understanding â†’ Storytelling  
- ğŸ—ºï¸ **Pan-Indian Coverage**: 5 geographical regions (North, South, East, West, Northeast)  
- ğŸš€ **Advanced LoRA Fine-tuning**: 85% performance improvement achieved  
- ğŸ“– **Authentic Narratives**: Culturally accurate stories preserving heritage  
- ğŸ’¡ **Research Innovation**: Novel progressive learning methodology  

## ğŸ›ï¸ Cultural Impact

> *Transforming silent cultural images into vivid, contextual narratives for digital heritage preservation.*

This project addresses the critical need for digital cultural preservation by:

- ğŸ“š **Documenting Stories**: Converting visual heritage into textual narratives  
- ğŸŒ **Accessibility**: Making cultural knowledge accessible globally  
- ğŸ”¬ **Research Tool**: Supporting cultural studies and heritage research  
- ğŸ“ **Education**: Enhancing cultural education through AI storytelling  

## ğŸ“Š Project Highlights

<div align="center">

| Metric | Achievement |
|--------|-------------|
| ğŸ“· Dataset Size | 1,360 curated cultural images |
| ğŸ§  Model Parameters | 2B (Qwen2-VL) with LoRA fine-tuning |
| ğŸ“ˆ Performance Improvement | 85% loss reduction (130 â†’ 19.7) |
| ğŸ—ºï¸ Regional Coverage | 5 major Indian geographical regions |
| ğŸ—ï¸ Training Methodology | 3-stage progressive learning |
| âœ… Cultural Accuracy | High-quality, authentic narratives |

</div>

## ğŸ—ï¸ 3-Stage Progressive Architecture

```mermaid
graph TD
    A[Cultural Image Input] --> B[ğŸ‘ï¸ Qwen2-VL Vision Encoder]
    B --> C[ğŸ§  Language Model Processing]
    C --> D[Stage 1: Element Recognition]
    D --> E[Stage 2: Pattern Understanding]
    E --> F[Stage 3: Story Generation]
    F --> G[ğŸ“– Cultural Story Output]
    
    D -.-> H[Identifies cultural elements]
    E -.-> I[Understands regional context]
    F -.-> J[Weaves authentic narratives]
```

### ğŸ” Stage 1 â€” Cultural Element Recognition  
- Identifies temples, sculptures, architectural features  
- Recognizes traditional clothing, artifacts, decorations  
- **Training:** 1 epoch, LR: `2e-4`

### ğŸ¨ Stage 2 â€” Cultural Pattern Understanding  
- Understands architectural styles (Dravidian, Mughal, etc.)  
- Analyzes regional patterns and significance  
- **Training:** 1 epoch, LR: `1e-4`

### ğŸ“š Stage 3 â€” Cultural Story Generation  
- Generates authentic, contextual narratives  
- Preserves cultural accuracy and historical context  
- **Training:** 2 epochs, LR: `5e-5`

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repository
git clone https://github.com/PranavSingla122/Cultural-Heritage-Story-Teller.git
cd Cultural-Heritage-Story-Teller

# Install dependencies
pip install -r requirements.txt

# Install additional requirements for vision-language models
pip install transformers[vision] torch torchvision peft accelerate bitsandbytes
```

### Basic Usage

```python
from inference import CulturalStoryTeller

# Initialize the model
storyteller = CulturalStoryTeller("./models/cultural_vlm_trained")

# Generate story from cultural image
image_path = "examples/temple_image.jpg"
story = storyteller.generate_story(image_path)
print(story)
```

### Example Output

```
This authentic East India scene while reveals a group of people walking across a bridge. The distinctive colonial calcutta showcases the region's unique architectural heritage and Regional cultural elements including poila boishakh, adda culture provide authentic local context. People adorned in traditional dress, ethnic wear embody the living culture....
```

## ğŸ“ Repository Structure

```
Cultural-Heritage-Story-Teller/
â”œâ”€â”€ ğŸ train_progressive.py       # Main 3-stage training pipeline
â”œâ”€â”€ ğŸ”§ continue_training.py       # Optional optimization script
â”œâ”€â”€ ğŸ”® inference.py               # Story generation from trained model
â”œâ”€â”€ ğŸ“Š dataset_utils.py           # Dataset loading and preprocessing
â”œâ”€â”€ ğŸ›ï¸ config.py                  # Training configuration
â”œâ”€â”€ ğŸ“‹ requirements.txt           # Python dependencies
â”œâ”€â”€ ğŸ“ data/                      # Dataset directory
â”‚   â””â”€â”€ cultural_dataset.json     # Your cultural image dataset
â”œâ”€â”€ ğŸ“ models/                    # Trained model checkpoints
â”‚   â””â”€â”€ cultural_vlm_trained/     # Final trained model
â”œâ”€â”€ ğŸ“ examples/                  # Usage examples and demos
â””â”€â”€ ğŸ“– README.md                  # This file
```

## ğŸ¯ Training Your Own Model

### Dataset Format

Your cultural dataset should follow this JSON structure:

```json
{
  "image_path": "regional_images/South_India/temple_001.jpg",
  "region": "South_India",
  "real_features": {
    "detected_elements": ["temple", "gopuram", "sculpture"],
    "architecture": {"style": "Dravidian"},
    "colors": {"dominant": ["brown", "red"]},
    "scene": {"type": "religious"}
  },
  "unique_story": "This ancient Dravidian temple stands as a testament...",
  "cultural_context": "South Indian temple architecture represents..."
}
```

### 3-Stage Progressive Training

```bash
# Run complete 3-stage progressive training
python train_progressive.py

# For testing with limited samples
python train_progressive.py --test_samples 100

# Single stage training (skip progressive approach)
python train_progressive.py --single_stage
```


## ğŸ“ˆ Training Results

<div align="center">

| Stage | Task | Loss Reduction | Key Learning |
|-------|------|----------------|--------------|
| 1 | Element Recognition | 504 â†’ 217 | Cultural artifact identification |
| 2 | Pattern Understanding | 217 â†’ 201 | Regional style comprehension |
| 3 | Story Generation | 184 â†’ 19.7 | Authentic narrative creation |

</div>

### Regional Dataset Distribution

<div align="center">

| Region | Samples | Coverage |
|--------|---------|----------|
| ğŸ”ï¸ **North India** | 160 | Rajasthan, Delhi, Himalayas |
| ğŸ›ï¸ **South India** | 400 | Tamil Nadu, Karnataka, Kerala |
| ğŸ­ **East India** | 400 | West Bengal, Odisha, Jharkhand |
| ğŸœï¸ **West India** | 200 | Gujarat, Maharashtra, Rajasthan |
| ğŸŒ„ **Northeast India** | 200 | Assam, Meghalaya, Sikkim |

</div>

## ğŸ› ï¸ Technical Specifications

### Model Architecture
- **Base Model**: Qwen2-VL-2B-Instruct
- **Fine-tuning**: LoRA (r=8, Î±=32, 7 target modules)
- **Quantization**: 4-bit with bfloat16 precision
- **Context Length**: 512 tokens
- **Image Resolution**: 336Ã—336 pixels

### Training Configuration
- **Optimizer**: AdamW with cosine scheduling
- **Memory Optimization**: Gradient checkpointing + quantization
- **Hardware Requirements**: 8 GB+ GPU recommended
- **Training Time**: ~3â€“5 hours for full pipeline

## ğŸ¤ Contributing

We welcome contributions from cultural enthusiasts, AI researchers, and heritage preservationists!

### How to Contribute

1. ğŸ´ **Fork** the repository
2. ğŸŒ¿ **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. ğŸ’¾ **Commit** your changes (`git commit -m 'Add some amazing feature'`)
4. ğŸ“¤ **Push** to the branch (`git push origin feature/amazing-feature`)
5. ğŸ”€ **Open** a Pull Request

### Contribution Areas

- ğŸ¨ **Dataset Expansion**: Adding more regional cultural images
- ğŸ”¬ **Model Improvements**: Enhancing training methodologies
- ğŸŒ **Multilingual Support**: Adding regional language stories
- ğŸ“± **Applications**: Building demo apps and interfaces
- ğŸ“– **Documentation**: Improving guides and examples


## ğŸ“œ License

This project is licensed under the **Apache License 2.0** â€“ see the [LICENSE](LICENSE) file for details.

<div align="center">

| Permission | Status |
|------------|--------|
| âœ… Commercial Use | Permitted |
| âœ… Modification | Permitted |
| âœ… Distribution | Permitted |
| âœ… Patent Use | Permitted |
| âš ï¸ Trademark Use | Not permitted |

</div>

## ğŸ™ Acknowledgments

- Thanks to the Qwen team for the amazing vision-language model
- Open source community for continuous support and contributions

---

<div align="center">

**â­ Star this repository if it helped preserve cultural heritage through AI!**

Story-Teller/issues) â€¢ [Discussions](https://github.com/PranavSingla122/Cultural-Heritage-Story-Teller/discussions)

</div>
